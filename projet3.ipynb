{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87c788ab",
   "metadata": {},
   "source": [
    "# Mini-projet n°3 - ViT vs CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce2fe8a",
   "metadata": {},
   "source": [
    "L'objectif de ce mini-projet est de comparer les performances de deux architectures différentes pour de la classification d'image : les Vision Transformers (ViT) et les Convolutional Neural Networks (CNN)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a85241",
   "metadata": {},
   "source": [
    "## Explication de l'architecture Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7d7a78-6b5b-4380-a137-bc0206686f9a",
   "metadata": {},
   "source": [
    "Les transformers ont initialement étaient inventés pour des problèmes NLP mais on peut aussi l'utiliser -comme ici- pour de la classification d'images. \n",
    "\n",
    "Avant le block Transformer, il y a l'input embedding qui se traduit par de la vectorisation des patchs d'images (découpe de l'image en patchs). Pour que le modèle sache où est ce que le patch se situe sur l'image et donc garder l'information spatiale, on ajoute un vecteur de position créé par le positional encoding.\n",
    "Après avoir fait cela, on entre dans l'encodeur qui est tout d'abord défini par un multi head attention. Cette \"opération\"/ ce procédé sert à capturer les diverses relations dans les données. C'est une transformation sur les données d'entrées qui permettent de prendre en compte les pondérations et les différences entre les éléments. **A developper avec key, query etc**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f88aa1-3587-42fe-afe3-0075558e6239",
   "metadata": {},
   "source": [
    "POur mettre en relation les différents patchs on va faire une matrice d'attention ds laulle il est ecrit ok tel patch a tel relation avec tel patch.\n",
    "query= question : cette matrice est optimisée comme key et value\n",
    "\n",
    "on a emvbedding et matrices d eprojections (q,v,k) entre la matrice et le token embeddé (apres embedding) et ca donne vecteurs et apres la fprmule de l'attention on peut avoir une matrice de relation entre les differents tokens (tokens=patch) - une heatmap-\n",
    "\n",
    "\n",
    "l'encoder permet de faier une representation des patchs avec projections dans un espace latent. puis le decoder prédit"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
